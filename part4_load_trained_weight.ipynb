{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version creates additional training examples by rotating each original by +/- 10 degrees\n",
    "# xytywh, 2019/06/19\n",
    "\n",
    "# 直接导入 part3_neural_network_mnist_data_with_rotations.ipynb 以及训练好的wih和who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy provides arrays and useful functions for working with them\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# scipy.ndimage for rotating image arrays\n",
    "import scipy.ndimage\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "\n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)),\n",
    "                                        numpy.transpose(hidden_outputs))\n",
    "\n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)),\n",
    "                                        numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "\n",
    "# 输入层和隐藏层之间的权重wih 以及 隐藏层和输出层之间的权重who直接导入文件\n",
    "# part3_neural_network_mnist_data_with_rotations.ipynb 已经训练好的权重即可，无需再次训练\n",
    "n.wih = numpy.load('wih.npy')\n",
    "n.who = numpy.load('who.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test_10000.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  97.87 %\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"accuracy = \", scorecard_array.sum() / scorecard_array.size*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... my_own_images/2.png\n",
      "[[7.49001481e-04]\n",
      " [3.14712429e-01]\n",
      " [9.83235319e-01]\n",
      " [1.84801649e-03]\n",
      " [2.60709030e-04]\n",
      " [4.16629884e-02]\n",
      " [3.25115713e-03]\n",
      " [6.37794550e-03]\n",
      " [8.51642414e-04]\n",
      " [3.43298892e-03]]\n",
      "network says  2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAEqVJREFUeJzt3X+MZXV5x/H3A2KQNQwRmt2mGERXkvUPTedaLdWVbTFB\naQL8hblqNtQ0hqKNmaTVmBih0MQIQWgl25gmBQ1yE4ylUAKsSvAHbWHtXDEiWALyQ113BEmGBEGR\nffrHvaszs7Ozc+/cO8/98X4lJ+Ge871zni/fO589c875nhuZiSSpxjHVBUjSNDOEJamQISxJhQxh\nSSpkCEtSIUNYkgoZwpJUyBCWpEKGsCQVekV1ARFxMnAO8ATwYm01kjQQxwOvA/Zm5i/Xaji0EI6I\njwB/B2wDvg/8bWZ+d5Wm5wBfHlYdklToA8BNazUYSghHxPuAq4EPA/uAOWBvRJyRmc+saP4EwI03\n3siOHTuWbZibm+Oaa64ZRonlJrlvMNn9s2/ja7P69/DDD/PBD34Quvm2lmEdCc8BX8jMLwFExMXA\nXwIfAq5c0fZFgB07djA7O7tsw8zMzGHrJsUk9w0mu3/2bXwV9O+op1gHfmEuIo4DGsDdh9Zl51Ft\n3wDOHPT+JGmcDePuiFOAY4GFFesX6JwfliR1eYuaJBUaxjnhZ4CXga0r1m8FDhzpTXNzc8zMzCxb\nd9pppw28uFHRbDarSxiqSe6ffRtfw+hfq9Wi1WotW7e4uLju98cwvlkjIu4D7s/Mj3VfB/AU8M+Z\nedWKtrPA/Pz8/ERfEJA0PdrtNo1GA6CRme212g7r7ojPATdExDy/v0XtBOCGIe1PksbSUEI4M2+O\niFOAy+mchngAOCcznx7G/iRpXA1txlxm7gH2DOvnS9Ik8O4ISSpkCEtSIUNYkgoZwpJUyBCWpEKG\nsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFD\nWJIKGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpkCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAh\nLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVGjg\nIRwRl0bEwRXLQ4PejyRNglcM6ec+CJwNRPf1b4e0H0kaa8MK4d9m5tND+tmSNDGGdU74jRHxs4h4\nLCJujIjXDmk/kjTWhhHC9wEXAecAFwOnA9+OiC1D2JckjbWBn47IzL1LXj4YEfuAJ4ELgesHvT9J\nGmfDOif8O5m5GBGPANvXajc3N8fMzMyydc1mk2azOczyJGlDWq0WrVZr2brFxcV1vz8yc9A1Ld9B\nxKuBp4BPZ+Z1q2yfBebn5+eZnZ0dai2StBna7TaNRgOgkZnttdoO4z7hqyLiXRFxWkT8GXAL8BLQ\nOspbJWnqDON0xKnATcDJwNPAvcCfZuYvh7AvSRprw7gw50lcSVonnx0hSYWGfneENK56uWh9zDGj\ncTwTEUdv1HXw4MEhVqL1Go1PjiRNKUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1Ih\nQ1iSCjltWYcZx+m66hjW2DnFeXj8DZKkQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQ\nlqRChrAkFXLa8ohxyvB06GUacC+fiWOPPXYoP1fD42+xJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIK\nGcKSVMgQlqRChrAkFTKEJamQ05Y3gVORO/zG3t+LiOoSNCIm9zdeksaAISxJhQxhSSpkCEtSIUNY\nkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFep62HBE7gb8HGsAfAhdk5m0r2lwO/DVwEvBfwN9k5qMb\nL1ebYVjTi52qKx2unyPhLcADwCXAYQ9FiIhPAB8FPgy8DXge2BsRr9xAnZI0kXo+Es7Mu4C7AGL1\nQ5uPAVdk5u3dNruBBeAC4Ob+S5WkyTPQc8IRcTqwDbj70LrMfA64HzhzkPuSpEkw6Atz2+icolhY\nsX6hu02StIR3R0hSoUE/1P0AEMBWlh8NbwW+t9Yb5+bmmJmZWbau2WzSbDYHXKIkDU6r1aLVai1b\nt7i4uO73Ry/f+nDYmyMOsuIWtYjYD1yVmdd0X59IJ5B3Z+ZXVvkZs8D8/Pw8s7OzfdcyysbtmzW8\nRW20jMLnZyM5MY3a7TaNRgOgkZnttdr2c5/wFmA7nSNegNdHxFuAZzPzJ8C1wKci4lHgCeAK4KfA\nrb3uS5ImXT+nI94K3EPnAlwCV3fXfxH4UGZeGREnAF+gM1njO8B7M/M3A6hXkiZKP/cJf4ujXNDL\nzMuAy/orSZKmh9+2vAl6ORc6Ct9I7LlbafPUXwWSpClmCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQl\nqZAhLEmFDGFJKmQIS1Ihpy2PGKcMT4dReDylRoOjK0mFDGFJKmQIS1IhQ1iSChnCklTIEJakQoaw\nJBUyhCWpkCEsSYUMYUkq5LRlaQB6mYYMozEVeRS+2VseCUtSKUNYkgoZwpJUyBCWpEKGsCQVMoQl\nqZAhLEmFDGFJKmQIS1IhQ1iSCjltWTqCcfxG5F6mIvvN3qNhND45kjSlDGFJKmQIS1IhQ1iSChnC\nklTIEJakQoawJBUyhCWpkCEsSYUMYUkq1HMIR8TOiLgtIn4WEQcj4rwV26/vrl+63DG4kqX+Zea6\nl2OOOWbdyzAdPHhw3UtErHvRaOjn07MFeAC4BDjS5Po7ga3Atu7S7Ks6SZpwPT/AJzPvAu4CiCP/\nc/rrzHx6I4VJ0jQY1t9RuyJiISJ+FBF7IuI1Q9qPJI21YTzK8k7gq8DjwBuAzwB3RMSZ2cuzASVp\nCgw8hDPz5iUvfxgRPwAeA3YB9wx6f5I0zob+UPfMfDwingG2s0YIz83NMTMzs2xds9mk2fSanqTR\n1Wq1aLVay9YtLi6u+/2xkTMEEXEQuCAzb1ujzanAk8D5mXn7Kttngfn5+XlmZ2f7rkVaD78tQ5uh\n3W7TaDQAGpnZXqttz0fCEbGFzlHtodF+fUS8BXi2u1xK55zwgW67zwKPAHt73ZckTbp+Tke8lc5p\nhewuV3fXf5HOvcNvBnYDJwH76YTvpzPzpQ1XK0kTpp/7hL/F2re2vaf/ciRpuozGSS9JmlJ+5b3G\nnhfbNM5G4xMpSVPKEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRCTlvWSBq3\nqci9TEMGpyLr9+o/vZI0xQxhSSpkCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKuS0\nZW2aSZ6K7DRk9av+ky5JU8wQlqRChrAkFTKEJamQISxJhQxhSSpkCEtSIUNYkgoZwpJUyBCWpEJO\nW54S4zZleFiciqxRM7m/bZI0BgxhSSpkCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFegrh\niPhkROyLiOciYiEibomIM1Zpd3lE7I+IX0XE1yNi++BKlqTJ0eu05Z3A54H/7b73M8DXImJHZr4A\nEBGfAD4K7AaeAP4R2Ntt85tBFS6nIvfD/w+jpZep4b1MOR8nPYVwZp679HVEXAT8AmgA93ZXfwy4\nIjNv77bZDSwAFwA3b7BeSZooGz0sOAlI4FmAiDgd2AbcfahBZj4H3A+cucF9SdLE6TuEo/N3xLXA\nvZn5UHf1NjqhvLCi+UJ3myRpiY08ynIP8CbgHQOqRZKmTl8hHBHXAecCOzPz50s2HQAC2Mryo+Gt\nwPfW+plzc3PMzMwsW9dsNmk2m/2UKEmbotVq0Wq1lq1bXFxc9/ujlyvs8LsAPh84KzN/vMr2/cBV\nmXlN9/WJdAJ5d2Z+ZZX2s8D8/Pw8s7OzPdUy7bw7QuNuUu+OaLfbNBoNgEZmttdq29ORcETsAZrA\necDzEbG1u2kxM1/s/ve1wKci4lE6t6hdAfwUuLWXfUnSNOj1dMTFdC68fXPF+r8CvgSQmVdGxAnA\nF+jcPfEd4L3eIyxJh+v1PuF1/U2bmZcBl/VRjyRNFU8USlIhv21ZUplhXVwep4t4HglLUiFDWJIK\nGcKSVMgQlqRChrAkFTKEJamQISxJhQxhSSpkCEtSIUNYkgo5bXmMTeqzWKVp4pGwJBUyhCWpkCEs\nSYUMYUkqZAhLUiFDWJIKGcKSVMgQlqRChrAkFTKEJamQ05anRC9TnCVtHo+EJamQISxJhQxhSSpk\nCEtSIUNYkgoZwpJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUy\nhCWpkCEsSYUMYUkqZAhLUiFDWJIK9RTCEfHJiNgXEc9FxEJE3BIRZ6xoc31EHFyx3DHYsiVpMvR6\nJLwT+DzwduDdwHHA1yLiVSva3QlsBbZ1l+YG65SkifSKXhpn5rlLX0fERcAvgAZw75JNv87Mpzdc\nnSRNuI2eEz4JSODZFet3dU9X/Cgi9kTEaza4H0maSD0dCS8VEQFcC9ybmQ8t2XQn8FXgceANwGeA\nOyLizMzMjRQrSZOm7xAG9gBvAt6xdGVm3rzk5Q8j4gfAY8Au4J4N7E+SJk5fIRwR1wHnAjsz8+dr\ntc3MxyPiGWA7a4Tw3NwcMzMzy9Y1m02aTa/pSRpdrVaLVqu1bN3i4uK63x+9niHoBvD5wFmZ+eN1\ntD8VeBI4PzNvX2X7LDA/Pz/P7OxsT7VI0ihqt9s0Gg2ARma212rb633Ce4APAO8Hno+Ird3l+O72\nLRFxZUS8PSJOi4izgf8AHgH29tMZSZpkvd4dcTFwIvBNYP+S5cLu9peBNwO3Av8H/CvwXeBdmfnS\nAOqVpInS633Ca4Z2Zr4IvGdDFUnSFPHZEZJUyBCWpEKGsCQVMoQlqZAhLEmFDGFJKmQIS1IhQ1iS\nChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIKjXQIr/zyvEkyyX2Dye6ffRtfo9g/\nQ7jIJPcNJrt/9m18jWL/RjqEJWnSGcKSVMgQlqRCPX3b8pAcD/Dwww8ftmFxcZF2u73pBW2GSe4b\nTHb/7Nv42qz+Lcmz44/WNjJzuNUcrYCI9wNfLi1CkobjA5l501oNRiGETwbOAZ4AXiwtRpIG43jg\ndcDezPzlWg3LQ1iSppkX5iSpkCEsSYUMYUkqZAhLUqGRDOGI+EhEPB4RL0TEfRHxJ9U1DUJEXBoR\nB1csD1XX1Y+I2BkRt0XEz7r9OG+VNpdHxP6I+FVEfD0itlfU2o+j9S8irl9lLO+oqne9IuKTEbEv\nIp6LiIWIuCUizlil3ViO3Xr6N2pjN3IhHBHvA64GLgX+GPg+sDciTiktbHAeBLYC27rLO2vL6dsW\n4AHgEuCwW2wi4hPAR4EPA28Dnqczjq/czCI3YM3+dd3J8rFsbk5pG7IT+DzwduDdwHHA1yLiVYca\njPnYHbV/XaMzdpk5UgtwH/BPS14H8FPg49W1DaBvlwLt6jqG0K+DwHkr1u0H5pa8PhF4Abiwut4B\n9e964N+raxtA307p9u+dEzp2q/VvpMZupI6EI+I4oAHcfWhddv6vfQM4s6quAXtj90/cxyLixoh4\nbXVBgxYRp9M5ulg6js8B9zM54wiwq/sn748iYk9EvKa6oD6cROdI/1mYyLFb1r8lRmbsRiqE6fyr\ndSywsGL9Ap0Pxri7D7iIzgzBi4HTgW9HxJbKooZgG50P/qSOI3T+nN0N/AXwceAs4I6IiNKqetCt\n9Vrg3sw8dG1iYsbuCP2DERu7UXiAz9TIzL1LXj4YEfuAJ4EL6fyJpDGRmTcvefnDiPgB8BiwC7in\npKje7QHeBLyjupAhWbV/ozZ2o3Yk/AzwMp0T5kttBQ5sfjnDlZmLwCPAWFx57sEBOufyp2IcATLz\ncTqf37EYy4i4DjgX2JWZP1+yaSLGbo3+HaZ67EYqhDPzJWAeOPvQuu6fCGcD/11V17BExKvpDPya\nH5Jx0/1QH2D5OJ5I54r1xI0jQEScCpzMGIxlN6DOB/48M59aum0Sxm6t/h2hfenYjeLpiM8BN0TE\nPLAPmANOAG6oLGoQIuIq4D/pnIL4I+AfgJeA0fviq6PonsfeTueoCeD1EfEW4NnM/Amdc3GfiohH\n6Twh7wo6d7ncWlBuz9bqX3e5FPgqncDaDnyWzl81ew//aaMjIvbQuR3rPOD5iDh0xLuYmYeeYji2\nY3e0/nXHdbTGrvr2jCPcVnIJncF/Afgf4K3VNQ2oXy06H+YXgKeAm4DTq+vqsy9n0bn15+UVy78t\naXMZndudfkXnA769uu5B9I/OYwrvovNL/CLwY+BfgD+ornsd/VqtTy8Du1e0G8uxO1r/RnHsfJSl\nJBUaqXPCkjRtDGFJKmQIS1IhQ1iSChnCklTIEJakQoawJBUyhCWpkCEsSYUMYUkqZAhLUiFDWJIK\n/T9dBQuh5Dc7JQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19e8ca69dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... my_own_images/2.png\")\n",
    "img_array = imageio.imread('my_own_images/2.png', as_gray=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
